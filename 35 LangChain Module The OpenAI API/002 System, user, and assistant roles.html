<p>Hey everyone!</p><p>Last time, we started creating our chat completion object. We left it off at the messages parameterâ€”a list of dictionaries where we can specify prompts as a system, a user, or an assistant.</p><p>Letâ€™s now discuss each of these roles individually.</p><p>The <strong>system role</strong> is typically used for directing the model; it defines the model's purpose, persona, output format, and any other necessary instructions. Providing the bot with a system message guarantees a better response for your specific use case.</p><p>For instance, if you were to create a grammar corrector, an appropriate system message would be:<br><em>You will be provided with statements, and your task is to convert them to standard English.</em></p><p>If you were to create a chatbot with a sarcastic twist instead, you could give it the following instructions:<br><em>You are Marv, a chatbot that reluctantly answers questions with sarcastic responses.</em></p><p>(For more ideas on possible system prompts, refer to <a href="https://platform.openai.com/docs/examples" rel="noopener noreferrer" target="_blank">OpenAIâ€™s webpage</a>.)</p><p>The second role on our list is the <strong>user role</strong>. This is <strong>you</strong>. The content you pass as a user can range from a question you need answered to a sentence you want extended, to a paragraph requiring grammar corrections, and much more.</p><p>The third type of message we can include in our prompt to the model is an <strong>assistant message</strong>. Assistant messages can be used whenever we want to provide the model with example outputs to give additional context or guide it toward the writing style.</p><p>As an example, imagine we train a chatbot to perform sentiment analysis. So, we pass the following sequence of system, user, and assistant messages. First comes a system message reading:<br><em>You will be provided with a tweet, and your task is to classify its sentiment as positive, neutral, or negative.</em></p><p>Then, we feed a user message with the following content:<br><em>This new movie is extraordinary!</em></p><p>An assistant message then helps the model identify that as a positive tweet.</p><p>We follow up with a second example reading:<br><em>This new album is all right.</em></p><p>An assistant message then notes that this tweet has a neutral tone.</p><p>Letâ€™s now give an example of a negative tweet. Iâ€™ve chosen the following:<br><em>This new book could not have been written worse!</em></p><p>As usual, an assistant message then describes the sentiment, which, in this case, is negative. The model should now have understood its purpose and the way in which it must answer.</p><p>Imagine we now passed the following user message:<br><em>This new song blew my mind!</em></p><p>Had we not provided the system message or these couple of examples, the response to that message wouldâ€™ve likely been something as follows:<br><em>Thatâ€™s great to hear! Music has such a powerful impact. Whatâ€™s the song, and what did you find most striking about it?</em></p><p>But we would expect our instructed chatbot to respond with â€˜Positive.â€™</p><p>As a final remark, note that the modelâ€™s response is also considered an assistant-role message. In the next lesson, weâ€™ll see this explicitly in the code.</p><p>All right!</p><p>Iâ€™m confident youâ€™ve grasped the idea behind each role type, which will prove crucial in our LangChain discussion shortly.</p><p>Now, itâ€™s time to return to our notebook and continue implementing our chatbot.</p><p>See you in a bit! ðŸ˜Š</p>