<p>Welcome back, everyone, to this section on tokens, OpenAI models, and model pricing.</p><p>Youâ€™ve likely used ChatGPT and know it works by sending a prompt to the model and expecting a text answer. The question is, how does the model make sense of this text? How does it understand the meaning of the words and their mutual connection? How is it able to devise a response? This, of course, is a challenging question to answer. But in this lesson, weâ€™ll look at one aspect that makes this possible: tokenization.</p><p>Tokenization is a process whereby text inputs and outputs are broken down into sequences of characters called â€˜tokens.â€™ The unique tokens that an LLM operates form the vocabulary of this LLMâ€”a token amounts to roughly 3/4 of a word. An easier way of remembering this is to consider that 100 tokens correspond to approximately 75 words. So, when talking about OpenAIâ€™s tokenizing mechanism, a token isnâ€™t necessarily a single character or a word but rather a sequence of characters frequently seen together.</p><p>The task of a language model is to understand the statistical relationship between the tokens in its vocabulary. Once it does so, it can predict the token that is statistically most likely to occur next in a sentence. It then does so with the next token and the nextâ€”ending up with a text completion model.</p><p>You might think that this definition of a token as roughly 3/4 of a word might seem a bit arbitrary. Why not define tokens as short as a characterâ€”or as long as a phrase? Well, of course, itâ€™s a trade-off.</p><p>Surely, making the tokens smaller reduces your vocabulary, which, in turn, makes the model more memory efficient. Additionally, smaller tokens allow for a more agile model that learns new words and languages more easily. Still, this could make it harder for the model to capture the semantic meaning of texts. As you can imagine, predicting the next word in a sentence is easier than predicting the next character.</p><p>On the contrary, larger tokens could provide better context. But this comes at the cost of increased vocabulary size. Imagine we defined a token roughly as a sentence rather than a word. This means that even the slightest modifications to this sentence would result in different tokens. Again, itâ€™s easy to imagine that predicting the next word in a sentence is much easier than predicting the next sentence in a paragraph. So, the sweet spot of token sizes is somewhere in the middle. ðŸ˜Š</p><p>Okay, I hope you now have a good understanding of what tokens are.</p><p>In the next lesson, weâ€™ll use this knowledge to discuss different OpenAI models, their context window limits, and different pricing points.</p>