{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8612d1ba-630d-42f3-a20a-d749516d2cb5",
   "metadata": {},
   "source": [
    "# Importing the Relevant Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9ea1a0-3ff1-432f-ba3f-4375114b536d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile as sf\n",
    "import speech_recognition as sr\n",
    "\n",
    "from jiwer import wer, cer\n",
    "from IPython.display import Audio\n",
    "\n",
    "import whisper\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import tempfile\n",
    "import wave\n",
    "\n",
    "from gtts import gTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09353820-ee0a-46bb-8793-718a15e76de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a651422a-465f-4152-8ab7-1ebcbe069a73",
   "metadata": {},
   "source": [
    "# Loading and Visualizing an Audio File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05df4f9a-55e1-4c8e-85ad-ab89dd52e6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_signal, sample_rate = librosa.load('speech_01.wav', sr=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2bd363-5b30-490e-a0d2-ba8991e6e27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a780b2c0-8005-4e2d-b9d6-783e933fe461",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "librosa.display.waveshow(audio_signal, sr=sample_rate)\n",
    "plt.title('Waveform')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()\n",
    "\n",
    "# Play the audio in the notebook\n",
    "Audio('speech_01.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb8a14d-081f-4f6b-bdf9-f59ffb4fd533",
   "metadata": {},
   "source": [
    "# Transcribing Audio with Google Web Speech API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0a1293-18be-44dd-8b46-633dde1dc4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5ce335-0662-4c5f-8b68-61ea2747003e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'speech_01.wav' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae69a881-18f6-4c34-bfb8-1aaf188fef0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(file_path):\n",
    "    with sr.AudioFile(file_path) as source:\n",
    "        audio_data = recognizer.record(source)\n",
    "        text = recognizer.recognize_google(audio_data)\n",
    "        print(text)\n",
    "        return text    \n",
    "transcribed_text = transcribe_audio(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbacc5a0-bf75-4875-ae49-01bf196a8faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = \"\"\"My name is Ivan and I am excited to have you as part of our learning community! \n",
    "Before we get started, I’d like to tell you a little bit about myself. I’m a sound engineer turned data scientist,\n",
    "curious about machine learning and Artificial Intelligence. My professional background is primarily in media production,\n",
    "with a focus on audio, IT, and communications\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624277d2-e069-4da7-9174-d14332d86841",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_wer = wer(ground_truth, transcribed_text)\n",
    "calculated_cer = cer(ground_truth, transcribed_text)\n",
    "print(f\"Word Error Rate (WER): {calculated_wer:.4f}\")\n",
    "print(f\"Character Error Rate (CER): {calculated_cer:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a02896a-ad39-4efc-b64e-6f6b33b9f78f",
   "metadata": {},
   "source": [
    "# Background Noise and Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53e854b-1988-4be3-8563-c5c1a8085317",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "librosa.display.waveshow(audio_signal, sr=sample_rate)\n",
    "plt.title('Waveform')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()\n",
    "\n",
    "# Play the audio in the notebook\n",
    "Audio('speech_01.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e855e070-1114-46ed-bc9c-b7ae3bdacdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the spectrogram\n",
    "S = librosa.stft(audio_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b588571-b78f-4292-b66b-73aec4e4a52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_dB = librosa.amplitude_to_db(abs(S), ref=np.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cfb8bc-d5c7-4a4d-9437-1d386e0d5bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(S_dB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7c208a-562e-4b66-80a4-3ef13aa7b672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the spectrogram\n",
    "plt.figure(figsize=(12, 4))\n",
    "librosa.display.specshow(data = S_dB, sr=sample_rate, x_axis='time', y_axis='log')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Spectrogram')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892a3d58-d5c1-4d3f-be29-edeb322fff78",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_filtered = librosa.effects.preemphasis(audio_signal, coef=0.97)\n",
    "sf.write('filtered_speech_01.wav', signal_filtered, sample_rate)\n",
    "output_file = 'filtered_speech_01.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb806d2-328c-4e8e-b214-91b0cc6735f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play the original audio file\n",
    "print(\"Playing original audio:\")\n",
    "Audio(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0acee40-c562-47a6-9c60-68460d612603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play the filtered audio file\n",
    "print(\"Playing filtered audio:\")\n",
    "Audio(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8152275-061d-4aff-bc56-1a3a3d602040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the spectrogram\n",
    "Sb = librosa.stft(signal_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5763f50c-8f1a-448e-81ad-f8b9d2eeddd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_dBb = librosa.amplitude_to_db(abs(Sb), ref=np.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2326c5f-d8ad-45d9-8ee6-99daaa4a75d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the spectrogram\n",
    "plt.figure(figsize=(12, 4))\n",
    "librosa.display.specshow(data = S_dBb, sr=sample_rate, x_axis='time', y_axis='log')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Spectrogram')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c6c55f-8623-4271-a559-57cee6358304",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcribed_text_preemphasis = transcribe_audio('filtered_speech_01.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a255dd-eb56-4bc9-8ef3-8078376f6225",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_wer = wer(ground_truth, transcribed_text_preemphasis)\n",
    "calculated_cer = cer(ground_truth, transcribed_text_preemphasis)\n",
    "print(f\"Word Error Rate (WER): {calculated_wer:.4f}\")\n",
    "print(f\"Character Error Rate (CER): {calculated_cer:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704ea312-12d2-41d1-87c8-a7abd2230807",
   "metadata": {},
   "source": [
    "# Transciribing Audio with OpenAI's Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cbea07-9738-4c7f-96c0-9e7b533b0794",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eabe00-52d4-43b1-b4eb-42eff68df4b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = model.transcribe(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e970e7-234a-4353-b253-386ac648313e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcribed_text_whisper = result[\"text\"]\n",
    "transcribed_text_whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e436b9c0-8396-445e-88b3-979a5c2821b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"language\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5524e63d-99c3-4ba1-9f02-f97363f19f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_wer = wer(ground_truth, transcribed_text_whisper)\n",
    "calculated_cer = cer(ground_truth, transcribed_text_whisper)\n",
    "print(f\"Word Error Rate (WER): {calculated_wer:.4f}\")\n",
    "print(f\"Character Error Rate (CER): {calculated_cer:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57da8438-3d5a-488d-bb3b-b1471750e7b9",
   "metadata": {},
   "source": [
    "# Transcribing Multiple Audio Files from a Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844d9873-2a68-44ea-a3bc-32adc9dd8eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"C:/Users/PC/Downloads/Speech Recognition/Recordings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac29861-6e2a-4887-b045-0956be660424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_directory_whisper(directory_path):\n",
    "    transcriptions = []\n",
    "    for file_name in os.listdir(directory_path):\n",
    "        if file_name.endswith(\".wav\"):\n",
    "            files_path = os.path.join(directory_path, file_name)\n",
    "            # Transcribe the audio file\n",
    "            result = model.transcribe(files_path)\n",
    "            transcription = result[\"text\"]\n",
    "            transcriptions.append({\"file_name\": file_name, \"transcription\": transcription})\n",
    "    return transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0925ebd4-447c-4a8f-9b25-04341ecb0868",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcriptions = transcribe_directory_whisper(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb4aa00-46d6-4e66-869b-7801be3a0ac6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transcriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e98e47-022f-407f-8640-2201490cc799",
   "metadata": {},
   "source": [
    "# Saving Audio Transcriptions to CSV for Easy Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea7208c-d078-4f21-beac-b1f95ac66ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"transcriptions.csv\"\n",
    "\n",
    "with open(output_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Track Number\", \"File Name\", \"Transcription\"])  # Write the header\n",
    "    for number, transcription in enumerate(transcriptions, start=1):\n",
    "        writer.writerow([number, transcription['file_name'], transcription['transcription']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af47b56-2b3e-494c-8f2b-cea3242bf996",
   "metadata": {},
   "source": [
    "# Text-to-Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddfd5fc-ed70-41b5-a1df-eae35bc1537a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Thank you for taking the time to watch our course on speech recognition!\n",
    "This concludes the final lesson of this section. See you soon!\"\"\"\n",
    "\n",
    "tts = gTTS(text=text, lang='en')\n",
    "tts.save(\"output.mp3\")\n",
    "\n",
    "os.system(\"start output.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6142e8f8-e0f5-42b9-97a1-5583179924ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(speech_env)",
   "language": "python",
   "name": "speech_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
